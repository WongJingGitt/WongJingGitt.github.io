- ### 序：

    先贴一下项目的链接：[Auto Flow AI](https://github.com/WongJingGitt/AutoFlowAI)

    事情的起因是换了新项目组需要做UI自动化，所以决定重新从零开始搭建一下UI自动化框架，温习一下以前的一些技术，顺带验证一下对于框架搭建一些新的想法。  
    
    在封装DOM元素捕获的方法时，想起了UI自动化最大的弊端：**太过于依赖DOM了。** 特别是在学习了一些前端知识之后，我愈发这样觉得。
    有时候一个组件可能样式外观没什么变化，但是背地里DOM层级与DOM选择器全都变了。<span style="color: rgb(198, 202, 205)">我当初就有过因为开发把导航栏的类名与DOM层级重构了，导致我所有的UI自动化用例都没跑起来。 = =</span>

    这也是在搭框架时，为什么要把DOM选择器与业务逻辑分离的重要原因之一。

    所以我就在想，**为什么人在操作界面的时候不需要DOM选择器？** <span style="color: rgb(198, 202, 205)">现在回过头想这个问题好幼稚 = =</span>

    怀这个问题，我去打开了一个网站，带着这个问题体验了下。

    我发现人在浏览网页、操作某个元素的时候，首先是通过外观识别一个页面组件，然后再脑海中把它归类到一个指定的分类中。
    
    例如，我在看某个库的文档的时候，首先第一步是观察整体的布局，然后识别导航栏在哪里。然后在导航栏里面找 `Docs` 字段。
    
    总结了一下，这里面主要有两个很重要的因素： 

    1. **视觉处理。**  
    2. **文字识别。** 

    仔细一想这两点其实就是`物体检测分类`与`OCR文字识别`，并且现在都有对应的解决方案了。

    那么也就是说：**其实机器也可以像人一样依靠视觉与文字来识别组件！**  
    
    所以就有了这个想法。

    有了这个想法之后，开始去了解相关的算法模型。最终选择了两个模型：`YOLO v8` 与 `Paddleocr`。  

- ### 模型介绍：
  
    - #### YOLO v8：
      
        [YOLO](https://pjreddie.com/) 全称是 `You Only Look Once` ，是由 `Joseph Chet Redmon` 开源的一个目标检测的模型。  
        但是这位老哥因为担心技术被滥用，特别是军事应用与隐私问题。所以在YOLO v3之后，他停止了YOLO的更新。  
  
        但是！虽然他停止开发，其他人仍然在更新这个项目。例如 [YOLO v6](https://github.com/meituan/YOLOv6)就是美团开源的，没错就是美团外卖那个美团。
        
        而[YOLO v8](https://github.com/ultralytics/ultralytics)则是由[ultralytics](https://ultralytics.com/)公司开源的，也是YOLO目前(2023/09)最新的版本。  
  
    - #### Paddleocr：
  
        [Paddleocr](https://github.com/PaddlePaddle/PaddleOCR)是百度PP飞桨开源的OCR文字识别框架，并且自带了预训练模型，基本可以做到开箱即用。 
  
        没啥好特别介绍的，因为是百度开源的，所以它的预训练模型对于中文的识别很好。个人实际体验中文的识别准确度在95%以上，很少出现识别错误。  
  
- ### 实操：

    实际使用中，Paddleocr是有预训练模型的，无需进行额外的训练。
    
    主要需要训练的是YOLO模型。  
    
    训练YOLO模型需要制作训练数据集，在制作时参考的了COCO数据集。

    - **数据集的制作：**
        
        关于制作数据集，需要对元素的位置进行标记进行。
  
        YOLO的标记方式是：
  
        