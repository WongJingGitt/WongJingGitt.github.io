- ### 序：

    先贴一下项目的链接：[Auto Flow AI](https://github.com/WongJingGitt/AutoFlowAI)

    事情的起因是换了新项目组需要做UI自动化，所以决定重新从零开始搭建一下UI自动化框架，温习一下以前的一些技术，顺带验证一下对于框架搭建一些新的想法。  
    
    在封装DOM元素捕获的方法时，想起了UI自动化最大的弊端：**太过于依赖DOM了。** 特别是在学习了一些前端知识之后，我愈发这样觉得。
    有时候一个组件可能样式外观没什么变化，但是背地里DOM层级与DOM选择器全都变了。<span style="color: rgb(198, 202, 205)">我当初就有过因为开发把导航栏的类名与DOM层级重构了，导致我所有的UI自动化用例都没跑起来。 = =</span>

    这也是在搭框架时，为什么要把DOM选择器与业务逻辑分离的重要原因之一。

    所以我就在想，**为什么人在操作界面的时候不需要DOM选择器？** <span style="color: rgb(198, 202, 205)">现在回过头想这个问题好幼稚 = =</span>

    怀这个问题，我去打开了一个网站，带着这个问题体验了下。

    我发现人在浏览网页、操作某个元素的时候，首先是通过外观识别一个页面组件，然后再脑海中把它归类到一个指定的分类中。
    
    例如，我在看某个库的文档的时候，首先第一步是观察整体的布局，然后识别导航栏在哪里。然后在导航栏里面找 `Docs` 字段。
    
    总结了一下，这里面主要有两个很重要的因素： 

    1. **视觉处理。**  
    2. **文字识别。** 

    仔细一想这两点其实就是`物体检测分类`与`OCR文字识别`，并且现在都有对应的解决方案了。

    那么也就是说：**其实机器也可以像人一样依靠视觉与文字来识别组件！**  
    
    所以就有了这个想法。

    有了这个想法之后，开始去了解相关的算法模型。最终选择了两个模型：`YOLO v8` 与 `Paddleocr`。  

- ### 模型介绍：
  
    - #### YOLO v8：
      
        [YOLO](https://pjreddie.com/) 全称是 `You Only Look Once` ，是由 `Joseph Chet Redmon` 开源的一个目标检测的模型。  
        但是这位老哥因为担心技术被滥用，特别是军事应用与隐私问题。所以在YOLO v3之后，他停止了YOLO的更新。  
  
        但是！虽然他停止开发，其他人仍然在更新这个项目。例如 [YOLO v6](https://github.com/meituan/YOLOv6)就是美团开源的，没错就是美团外卖那个美团。
        
        而[YOLO v8](https://github.com/ultralytics/ultralytics)则是由[ultralytics](https://ultralytics.com/)公司开源的，也是YOLO目前(2023/09)最新的版本。  
  
    - #### Paddleocr：
  
        [Paddleocr](https://github.com/PaddlePaddle/PaddleOCR)是百度PP飞桨开源的OCR文字识别框架，并且自带了预训练模型，基本可以做到开箱即用。 
  
        没啥好特别介绍的，因为是百度开源的，所以它的预训练模型对于中文的识别很好。个人实际体验中文的识别准确度在95%以上，很少出现识别错误。  
  
- ### 实操：

    实际使用中，Paddleocr是有预训练模型的，无需进行额外的训练。
    
    主要需要训练的是YOLO模型。  
    
    训练YOLO模型需要制作训练数据集，在制作时参考的了COCO数据集。

    - **手工制作数据集：**
        
        制作YOLO数据集时需要对图片中的目标进行标记，最常用的工具是`labelImg`。  

        我在最初的数据集制作时也是使用`labelImg`，但是标注了部分数据之后我发现这样**制作数据效率实在是太低了**：
  
        1. 打开项目地址，然后对各个页面进行截图保存。
        2. 用`labelImg`打开截图文件夹，手动圈选目标DOM。
        3. 圈选了目标DOM之后，需要手动输入对应的label。
      
        当一个图片中有10个需要标注的DOM时，需要重复步骤2、步骤3十次，而且这些标注DOM往往都会有大量重复的DOM组件。
        
        > 举一个很典型的例子：导航栏的标注，一个导航栏下面可能有几个甚至十几个item。而这些item可能只是文案不同，例如：订单管理、人员管理、权限管理 ......
  
        而在使用`labelImg`进行标注时，你必须老老实实把所有的item都进行圈选，并且绑定label。一张图片标注完可能需要好几分钟，效率极低。  

        在我标注了半小时数据，发现只标注了7张图片之后，我决心一定要寻找一种快速指标数据集的方法。  

    - **脚本制作数据集：**  
        
        有了这个想法之后，我大致整理了下思路。既然是对DOM的标注，首先就需要捕获DOM。  
  
        这里的捕获DOM与UI自动化中的捕获DOM不同，
        UI自动化需要捕获到某个指定的DOM，例如：登录按钮。  
        而数据集的制作不需要定位到详细的DOM，只需要捕获所有某个类型的DOM即可，例如：页面所有的按钮。  
        
        这里我首先想到的是，使用TagName来捕获所有的元素。就像这样：

        ![](https://wongjinggitt.github.io/images/自动化/UI自动化/AI大模型与UI自动化/使用TagName捕获元素.png)

        但是实际使用中我发现，前端项目的组件往往会有很多不确定性。有一些组件TagName的位置，与这个组件在前端实际展示的位置是不相符的。  
        听起来可能有点抽象，这里面可能涉及到CSS组件设计相关的内容。总之据具体就像这样：

        ![](https://wongjinggitt.github.io/images/自动化/UI自动化/AI大模型与UI自动化/TagName偏移.png)
        
        从这个例子可以看见，如果使用TagName，则拿到的位置其实是搜索框里面，那这样的标注肯定是无效的，因为它没有给模型输入整个搜索框，而是输入了搜索框的内部。  
        
        还有一些场景也有很大的问题，例如按钮可以使用`<button></button>`来写，还可以使用`<input type="button"/>`

        得出了一个粗略的逻辑：  
        
        1. 
        2. 使用`Playwright`打开项目的目标URL。
        3. 页面加载完之后，在页面搜寻